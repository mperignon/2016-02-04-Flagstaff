{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since by now you have all written some Python code that works, we are going to jump directly into doing some science tasks with data pulled directly from real sources, instead of using a dataset we cleaned for you.\n",
    "\n",
    "Some of the stuff we are going to do will be fairly advanced but I think that seeing how the language can automate your workflow - and especially how it can handle the tasks that are annoying or difficult - will make it more likely that you'll come back to it. We are throwing a lot at you, so put a red sticky up if you need hands-on help and interrupt if you have a question, and we'll adjust as we go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the comparing the discharge over a specific time period at different points along the Colorado River. The traditional way to do this is through the USGS website:\n",
    "\n",
    "http://waterwatch.usgs.gov/?m=real&r=az\n",
    "\n",
    "and then precisely selecting the station you want and going through the whole process by hand. At the end, you have end up with some csv files that look like this:\n",
    "\n",
    "http://waterdata.usgs.gov/az/nwis/uv?cb_00060=on&cb_00065=on&format=rdb&site_no=09380000&period=&begin_date=2016-01-01&end_date=2016-01-10\n",
    "\n",
    "The header is annoying because it doesn't always have the same number of lines. Depending on the specific options we selected, the table has a different number of columns. Automating the analysis of these files is rough, and it requires quite a bit of handholding in Excel. If we were to do this frequently or for many stations, the chances of introducing an error are high.\n",
    "\n",
    "Instead of doing this by hand, we are going to request the data through the USGS web services. Web services are automated tools for transfering data directly from machine to machine. Effectively, the code we write will ask a server for some data, and that server will hand it back to your code. The way that these commands and data are transferred is through an API (Application Programming Interface), which is essertially a set of functions and protocols for that interaction. We don't actually need to understand in detail what any of that means to use it, though - help pages are our friend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by getting data from the streamgage station at Lee's Ferry. We'll make a variable with the station number (which I looked up):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid token (<ipython-input-1-6f8681f3257f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-6f8681f3257f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    station = 09380000\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid token\n"
     ]
    }
   ],
   "source": [
    "station = 09380000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An integer cannot start with a zero, so Python doesn't know what we mean and produces a Syntax Error. Let's rewrite the station number as a string by putting it in quotes (single or double both work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station = '09380000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in data between two specific dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = '2016-01-01'\n",
    "end_date = '2016-01-10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is accesed through APIs using URLs that contain the different pieces of information that the server needs to identify the data that we need. The USGS has a nifty little tool for helping us compose the URL:\n",
    "\n",
    "http://waterservices.usgs.gov/rest/IV-Test-Tool.html\n",
    "\n",
    "Let's use that tool to create the URL for the data we want:\n",
    "\n",
    "http://waterservices.usgs.gov/nwis/iv/?format=rdb&sites=09380000&startDT=2016-01-01&endDT=2016-01-10&parameterCd=00060,00065\n",
    "\n",
    "If we go to that URL, we could just download that file and process it manually. We are not going to do that.\n",
    "\n",
    "Early today we used a Python library called numpy to handle arrays of data. `numpy arrays` are matrices and are great for doing calculations on data, but they can only contain floats or integers. Tabular data are best handled by spreadsheets where entries such as dates and times are in some useful format.\n",
    "\n",
    "One of the best options for working with tabular data in Python is the Python Data Analysis Library (a.k.a. Pandas). The Pandas library provides data structures, produces high quality plots with matplotlib (the plotting library we used earlier) and integrates nicely with other libraries that can use numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://waterservices.usgs.gov/nwis/iv/?format=rdb&sites=09380000&startDT=2016-01-01&endDT=2016-01-10&parameterCd=00060,00065'\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assigned the URL we want to the variable `url`, and imported the Pandas library and gave it the shortcut `pd`. Pandas has multiple functions for importing data into Python, and we can use both local paths (within our computers) or URLs to point to the data we want to import. Let's start by loading a file with streamgage data that has already been cleaned up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "CParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 12, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCParserError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-26b43124923a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m _parser_defaults = {\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_footer not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas/parser.c:7988)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas/parser.c:8244)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_rows (pandas/parser.c:8970)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._tokenize_rows (pandas/parser.c:8838)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.raise_parser_error (pandas/parser.c:22649)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 12, saw 2\n"
     ]
    }
   ],
   "source": [
    "pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is unhappy and cannot load our file. Pandas expects one line of column titles and then data with the same number of columns. The header in the file we want to read is making it appear like the number of columns change partway through the file.\n",
    "\n",
    "The Pandas documentation will show us how to tell the function to ignore the header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers:\n",
      "\n",
      "read_csv(filepath_or_buffer, sep=',', dialect=None, compression='infer', doublequote=True, escapechar=None, quotechar='\"', quoting=0, skipinitialspace=False, lineterminator=None, header='infer', index_col=None, names=None, prefix=None, skiprows=None, skipfooter=None, skip_footer=0, na_values=None, true_values=None, false_values=None, delimiter=None, converters=None, dtype=None, usecols=None, engine=None, delim_whitespace=False, as_recarray=False, na_filter=True, compact_ints=False, use_unsigned=False, low_memory=True, buffer_lines=None, warn_bad_lines=True, error_bad_lines=True, keep_default_na=True, thousands=None, comment=None, decimal='.', parse_dates=False, keep_date_col=False, dayfirst=False, date_parser=None, memory_map=False, float_precision=None, nrows=None, iterator=False, chunksize=None, verbose=False, encoding=None, squeeze=False, mangle_dupe_cols=True, tupleize_cols=False, infer_datetime_format=False, skip_blank_lines=True)\n",
      "    Read CSV (comma-separated) file into DataFrame\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the `online docs for IO Tools\n",
      "    <http://pandas.pydata.org/pandas-docs/stable/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : string or file handle / StringIO\n",
      "        The string could be a URL. Valid URL schemes include\n",
      "        http, ftp, s3, and file. For file URLs, a\n",
      "        host is expected. For instance, a local file could be\n",
      "        file ://localhost/path/to/table.csv\n",
      "    sep : string, default ','\n",
      "        Delimiter to use. If sep is None, will try to automatically determine\n",
      "        this. Regular expressions are accepted.\n",
      "    engine : {'c', 'python'}\n",
      "        Parser engine to use. The C engine is faster while the python engine is\n",
      "        currently more feature-complete.\n",
      "    lineterminator : string (length 1), default None\n",
      "        Character to break file into lines. Only valid with C parser\n",
      "    quotechar : string (length 1)\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default None\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "        Default (None) results in QUOTE_MINIMAL behavior.\n",
      "    skipinitialspace : boolean, default False\n",
      "        Skip spaces after delimiter\n",
      "    escapechar : string (length 1), default None\n",
      "        One-character string used to escape delimiter when quoting is QUOTE_NONE.\n",
      "    dtype : Type name or dict of column -> type, default None\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
      "        (Unsupported with engine='python')\n",
      "    compression : {'gzip', 'bz2', 'infer', None}, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer', then use gzip or\n",
      "        bz2 if filepath_or_buffer is a string ending in '.gz' or '.bz2',\n",
      "        respectively, and no decompression otherwise. Set to None for no\n",
      "        decompression.\n",
      "    dialect : string or csv.Dialect instance, default None\n",
      "        If None defaults to Excel dialect. Ignored if sep longer than 1 char\n",
      "        See csv.Dialect documentation for more details\n",
      "    header : int, list of ints, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the\n",
      "        data.  Defaults to 0 if no ``names`` passed, otherwise ``None``. Explicitly\n",
      "        pass ``header=0`` to be able to replace existing names. The header can be\n",
      "        a list of integers that specify row locations for a multi-index on the\n",
      "        columns E.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example are skipped). Note that this parameter\n",
      "        ignores commented lines and empty lines if ``skip_blank_lines=True``, so header=0\n",
      "        denotes the first line of data rather than the first line of the file.\n",
      "    skiprows : list-like or integer, default None\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file\n",
      "    index_col : int or sequence or False, default None\n",
      "        Column to use as the row labels of the DataFrame. If a sequence is given, a\n",
      "        MultiIndex is used. If you have a malformed file with delimiters at the end\n",
      "        of each line, you might consider index_col=False to force pandas to _not_\n",
      "        use the first column as the index (row names)\n",
      "    names : array-like, default None\n",
      "        List of column names to use. If file contains no header row, then you\n",
      "        should explicitly pass header=None\n",
      "    prefix : string, default None\n",
      "        Prefix to add to column numbers when no header, e.g 'X' for X0, X1, ...\n",
      "    na_values : str, list-like or dict, default None\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values\n",
      "    true_values : list, default None\n",
      "        Values to consider as True\n",
      "    false_values : list, default None\n",
      "        Values to consider as False\n",
      "    keep_default_na : bool, default True\n",
      "        If na_values are specified and keep_default_na is False the default NaN\n",
      "        values are overridden, otherwise they're appended to\n",
      "    parse_dates : boolean, list of ints or names, list of lists, or dict, default False\n",
      "        If True -> try parsing the index.\n",
      "        If [1, 2, 3] -> try parsing columns 1, 2, 3 each as a separate date column.\n",
      "        If [[1, 3]] -> combine columns 1 and 3 and parse as a single date column.\n",
      "        {'foo' : [1, 3]} -> parse columns 1, 3 as date and call result 'foo'\n",
      "        A fast-path exists for iso8601-formatted dates.\n",
      "    keep_date_col : boolean, default False\n",
      "        If True and parse_dates specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, default None\n",
      "        Function to use for converting a sequence of string columns to an\n",
      "        array of datetime instances. The default uses dateutil.parser.parser\n",
      "        to do the conversion. Pandas will try to call date_parser in three different\n",
      "        ways, advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by parse_dates) as arguments; 2) concatenate (row-wise) the string\n",
      "        values from the columns defined by parse_dates into a single array and pass\n",
      "        that; and 3) call date_parser once for each row using one or more strings\n",
      "        (corresponding to the columns defined by parse_dates) as arguments.\n",
      "    dayfirst : boolean, default False\n",
      "        DD/MM format dates, international and European format\n",
      "    thousands : str, default None\n",
      "        Thousands separator\n",
      "    comment : str, default None\n",
      "        Indicates remainder of line should not be parsed. If found at the\n",
      "        beginning of a line, the line will be ignored altogether. This parameter\n",
      "        must be a single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header`\n",
      "        but not by `skiprows`. For example, if comment='#', parsing\n",
      "        '#empty\\na,b,c\\n1,2,3' with `header=0` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point. E.g. use ',' for European data\n",
      "    nrows : int, default None\n",
      "        Number of rows of file to read. Useful for reading pieces of large files\n",
      "    iterator : boolean, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with ``get_chunk()``.\n",
      "    chunksize : int, default None\n",
      "        Return TextFileReader object for iteration. `See IO Tools docs for more\n",
      "        information\n",
      "        <http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_ on\n",
      "        ``iterator`` and ``chunksize``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c')\n",
      "    converters : dict, default None\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels\n",
      "    verbose : boolean, default False\n",
      "        Indicate number of NA values placed in non-numeric columns\n",
      "    delimiter : string, default None\n",
      "        Alternative argument name for sep. Regular expressions are accepted.\n",
      "    encoding : string, default None\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_\n",
      "    squeeze : boolean, default False\n",
      "        If the parsed data only contains one column then return a Series\n",
      "    na_filter : boolean, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file\n",
      "    usecols : array-like, default None\n",
      "        Return a subset of the columns.\n",
      "        Results in much faster parsing time and lower memory usage.\n",
      "    mangle_dupe_cols : boolean, default True\n",
      "        Duplicate columns will be specified as 'X.0'...'X.N', rather than 'X'...'X'\n",
      "    tupleize_cols : boolean, default False\n",
      "        Leave a list of tuples on columns as is (default is to convert to\n",
      "        a Multi Index on the columns)\n",
      "    error_bad_lines : boolean, default True\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
      "        returned. (Only valid with C parser)\n",
      "    warn_bad_lines : boolean, default True\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output. (Only valid with C parser).\n",
      "    infer_datetime_format : boolean, default False\n",
      "        If True and parse_dates is enabled for a column, attempt to infer\n",
      "        the datetime format to speed up the processing\n",
      "    skip_blank_lines : boolean, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    result : DataFrame or TextParser\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to see the documentation as a separate window within an iPython notebook is with a question mark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `read_csv` requires the first parameter (a filepath) and accepts many optional parameters (if not set, they use a default value). For example, `sep=','` is an optional function parameter that defines the column separator. By default, it's a comma.\n",
    "\n",
    "Let's try loading our file again. Because the columns in our file are separated by tabs, we need to set the `sep` parameter. To remove the header, we will also tell Pandas that lines that start with `#` are comments and it should not import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tz_cd</th>\n",
       "      <th>01_00060</th>\n",
       "      <th>01_00060_cd</th>\n",
       "      <th>02_00065</th>\n",
       "      <th>02_00065_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5s</td>\n",
       "      <td>15s</td>\n",
       "      <td>20d</td>\n",
       "      <td>6s</td>\n",
       "      <td>14n</td>\n",
       "      <td>10s</td>\n",
       "      <td>14n</td>\n",
       "      <td>10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 00:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>15200</td>\n",
       "      <td>P</td>\n",
       "      <td>9.74</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 00:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>14900</td>\n",
       "      <td>P</td>\n",
       "      <td>9.67</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 00:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>14600</td>\n",
       "      <td>P</td>\n",
       "      <td>9.62</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 00:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>14200</td>\n",
       "      <td>P</td>\n",
       "      <td>9.55</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 01:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>14000</td>\n",
       "      <td>P</td>\n",
       "      <td>9.49</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 01:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>13600</td>\n",
       "      <td>P</td>\n",
       "      <td>9.42</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 01:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>13400</td>\n",
       "      <td>P</td>\n",
       "      <td>9.37</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 01:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>13000</td>\n",
       "      <td>P</td>\n",
       "      <td>9.28</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 02:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>12700</td>\n",
       "      <td>P</td>\n",
       "      <td>9.23</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 02:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>12500</td>\n",
       "      <td>P</td>\n",
       "      <td>9.18</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 02:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>12200</td>\n",
       "      <td>P</td>\n",
       "      <td>9.12</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 02:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>12000</td>\n",
       "      <td>P</td>\n",
       "      <td>9.07</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 03:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>11700</td>\n",
       "      <td>P</td>\n",
       "      <td>9.01</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 03:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>11500</td>\n",
       "      <td>P</td>\n",
       "      <td>8.95</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 03:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>11300</td>\n",
       "      <td>P</td>\n",
       "      <td>8.91</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 03:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>11100</td>\n",
       "      <td>P</td>\n",
       "      <td>8.86</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 04:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>10900</td>\n",
       "      <td>P</td>\n",
       "      <td>8.81</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 04:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>10700</td>\n",
       "      <td>P</td>\n",
       "      <td>8.78</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 04:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>10500</td>\n",
       "      <td>P</td>\n",
       "      <td>8.72</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 04:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>10500</td>\n",
       "      <td>P</td>\n",
       "      <td>8.71</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 05:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>10300</td>\n",
       "      <td>P</td>\n",
       "      <td>8.67</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 05:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>10200</td>\n",
       "      <td>P</td>\n",
       "      <td>8.64</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 05:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>10100</td>\n",
       "      <td>P</td>\n",
       "      <td>8.62</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 05:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>10000</td>\n",
       "      <td>P</td>\n",
       "      <td>8.60</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 06:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>9940</td>\n",
       "      <td>P</td>\n",
       "      <td>8.58</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 06:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>9860</td>\n",
       "      <td>P</td>\n",
       "      <td>8.56</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 06:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>9780</td>\n",
       "      <td>P</td>\n",
       "      <td>8.54</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 06:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>9780</td>\n",
       "      <td>P</td>\n",
       "      <td>8.54</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-01 07:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>9780</td>\n",
       "      <td>P</td>\n",
       "      <td>8.54</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 16:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>11600</td>\n",
       "      <td>P</td>\n",
       "      <td>8.98</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 16:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>11800</td>\n",
       "      <td>P</td>\n",
       "      <td>9.03</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 17:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>12100</td>\n",
       "      <td>P</td>\n",
       "      <td>9.10</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 17:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>12300</td>\n",
       "      <td>P</td>\n",
       "      <td>9.13</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 17:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>12500</td>\n",
       "      <td>P</td>\n",
       "      <td>9.19</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 17:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>12800</td>\n",
       "      <td>P</td>\n",
       "      <td>9.24</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 18:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>13000</td>\n",
       "      <td>P</td>\n",
       "      <td>9.28</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 18:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>13200</td>\n",
       "      <td>P</td>\n",
       "      <td>9.34</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 18:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>13500</td>\n",
       "      <td>P</td>\n",
       "      <td>9.39</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 18:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>13700</td>\n",
       "      <td>P</td>\n",
       "      <td>9.44</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 19:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>14000</td>\n",
       "      <td>P</td>\n",
       "      <td>9.50</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 19:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>14200</td>\n",
       "      <td>P</td>\n",
       "      <td>9.53</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 19:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>14500</td>\n",
       "      <td>P</td>\n",
       "      <td>9.60</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 19:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>14700</td>\n",
       "      <td>P</td>\n",
       "      <td>9.65</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 20:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>15000</td>\n",
       "      <td>P</td>\n",
       "      <td>9.70</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 20:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>15300</td>\n",
       "      <td>P</td>\n",
       "      <td>9.75</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 20:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>15500</td>\n",
       "      <td>P</td>\n",
       "      <td>9.79</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 20:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>15600</td>\n",
       "      <td>P</td>\n",
       "      <td>9.82</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 21:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>15800</td>\n",
       "      <td>P</td>\n",
       "      <td>9.85</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 21:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>15800</td>\n",
       "      <td>P</td>\n",
       "      <td>9.86</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 21:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>15800</td>\n",
       "      <td>P</td>\n",
       "      <td>9.86</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 21:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>15700</td>\n",
       "      <td>P</td>\n",
       "      <td>9.84</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 22:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>15700</td>\n",
       "      <td>P</td>\n",
       "      <td>9.83</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 22:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>15600</td>\n",
       "      <td>P</td>\n",
       "      <td>9.82</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 22:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>15400</td>\n",
       "      <td>P</td>\n",
       "      <td>9.78</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 22:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>15200</td>\n",
       "      <td>P</td>\n",
       "      <td>9.74</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 23:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>15000</td>\n",
       "      <td>P</td>\n",
       "      <td>9.70</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 23:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>14800</td>\n",
       "      <td>P</td>\n",
       "      <td>9.66</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 23:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>14600</td>\n",
       "      <td>P</td>\n",
       "      <td>9.62</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09380000</td>\n",
       "      <td>2016-01-10 23:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>14300</td>\n",
       "      <td>P</td>\n",
       "      <td>9.56</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    agency_cd   site_no          datetime tz_cd 01_00060 01_00060_cd 02_00065  \\\n",
       "0          5s       15s               20d    6s      14n         10s      14n   \n",
       "1        USGS  09380000  2016-01-01 00:00   MST    15200           P     9.74   \n",
       "2        USGS  09380000  2016-01-01 00:15   MST    14900           P     9.67   \n",
       "3        USGS  09380000  2016-01-01 00:30   MST    14600           P     9.62   \n",
       "4        USGS  09380000  2016-01-01 00:45   MST    14200           P     9.55   \n",
       "5        USGS  09380000  2016-01-01 01:00   MST    14000           P     9.49   \n",
       "6        USGS  09380000  2016-01-01 01:15   MST    13600           P     9.42   \n",
       "7        USGS  09380000  2016-01-01 01:30   MST    13400           P     9.37   \n",
       "8        USGS  09380000  2016-01-01 01:45   MST    13000           P     9.28   \n",
       "9        USGS  09380000  2016-01-01 02:00   MST    12700           P     9.23   \n",
       "10       USGS  09380000  2016-01-01 02:15   MST    12500           P     9.18   \n",
       "11       USGS  09380000  2016-01-01 02:30   MST    12200           P     9.12   \n",
       "12       USGS  09380000  2016-01-01 02:45   MST    12000           P     9.07   \n",
       "13       USGS  09380000  2016-01-01 03:00   MST    11700           P     9.01   \n",
       "14       USGS  09380000  2016-01-01 03:15   MST    11500           P     8.95   \n",
       "15       USGS  09380000  2016-01-01 03:30   MST    11300           P     8.91   \n",
       "16       USGS  09380000  2016-01-01 03:45   MST    11100           P     8.86   \n",
       "17       USGS  09380000  2016-01-01 04:00   MST    10900           P     8.81   \n",
       "18       USGS  09380000  2016-01-01 04:15   MST    10700           P     8.78   \n",
       "19       USGS  09380000  2016-01-01 04:30   MST    10500           P     8.72   \n",
       "20       USGS  09380000  2016-01-01 04:45   MST    10500           P     8.71   \n",
       "21       USGS  09380000  2016-01-01 05:00   MST    10300           P     8.67   \n",
       "22       USGS  09380000  2016-01-01 05:15   MST    10200           P     8.64   \n",
       "23       USGS  09380000  2016-01-01 05:30   MST    10100           P     8.62   \n",
       "24       USGS  09380000  2016-01-01 05:45   MST    10000           P     8.60   \n",
       "25       USGS  09380000  2016-01-01 06:00   MST     9940           P     8.58   \n",
       "26       USGS  09380000  2016-01-01 06:15   MST     9860           P     8.56   \n",
       "27       USGS  09380000  2016-01-01 06:30   MST     9780           P     8.54   \n",
       "28       USGS  09380000  2016-01-01 06:45   MST     9780           P     8.54   \n",
       "29       USGS  09380000  2016-01-01 07:00   MST     9780           P     8.54   \n",
       "..        ...       ...               ...   ...      ...         ...      ...   \n",
       "931      USGS  09380000  2016-01-10 16:30   MST    11600           P     8.98   \n",
       "932      USGS  09380000  2016-01-10 16:45   MST    11800           P     9.03   \n",
       "933      USGS  09380000  2016-01-10 17:00   MST    12100           P     9.10   \n",
       "934      USGS  09380000  2016-01-10 17:15   MST    12300           P     9.13   \n",
       "935      USGS  09380000  2016-01-10 17:30   MST    12500           P     9.19   \n",
       "936      USGS  09380000  2016-01-10 17:45   MST    12800           P     9.24   \n",
       "937      USGS  09380000  2016-01-10 18:00   MST    13000           P     9.28   \n",
       "938      USGS  09380000  2016-01-10 18:15   MST    13200           P     9.34   \n",
       "939      USGS  09380000  2016-01-10 18:30   MST    13500           P     9.39   \n",
       "940      USGS  09380000  2016-01-10 18:45   MST    13700           P     9.44   \n",
       "941      USGS  09380000  2016-01-10 19:00   MST    14000           P     9.50   \n",
       "942      USGS  09380000  2016-01-10 19:15   MST    14200           P     9.53   \n",
       "943      USGS  09380000  2016-01-10 19:30   MST    14500           P     9.60   \n",
       "944      USGS  09380000  2016-01-10 19:45   MST    14700           P     9.65   \n",
       "945      USGS  09380000  2016-01-10 20:00   MST    15000           P     9.70   \n",
       "946      USGS  09380000  2016-01-10 20:15   MST    15300           P     9.75   \n",
       "947      USGS  09380000  2016-01-10 20:30   MST    15500           P     9.79   \n",
       "948      USGS  09380000  2016-01-10 20:45   MST    15600           P     9.82   \n",
       "949      USGS  09380000  2016-01-10 21:00   MST    15800           P     9.85   \n",
       "950      USGS  09380000  2016-01-10 21:15   MST    15800           P     9.86   \n",
       "951      USGS  09380000  2016-01-10 21:30   MST    15800           P     9.86   \n",
       "952      USGS  09380000  2016-01-10 21:45   MST    15700           P     9.84   \n",
       "953      USGS  09380000  2016-01-10 22:00   MST    15700           P     9.83   \n",
       "954      USGS  09380000  2016-01-10 22:15   MST    15600           P     9.82   \n",
       "955      USGS  09380000  2016-01-10 22:30   MST    15400           P     9.78   \n",
       "956      USGS  09380000  2016-01-10 22:45   MST    15200           P     9.74   \n",
       "957      USGS  09380000  2016-01-10 23:00   MST    15000           P     9.70   \n",
       "958      USGS  09380000  2016-01-10 23:15   MST    14800           P     9.66   \n",
       "959      USGS  09380000  2016-01-10 23:30   MST    14600           P     9.62   \n",
       "960      USGS  09380000  2016-01-10 23:45   MST    14300           P     9.56   \n",
       "\n",
       "    02_00065_cd  \n",
       "0           10s  \n",
       "1             P  \n",
       "2             P  \n",
       "3             P  \n",
       "4             P  \n",
       "5             P  \n",
       "6             P  \n",
       "7             P  \n",
       "8             P  \n",
       "9             P  \n",
       "10            P  \n",
       "11            P  \n",
       "12            P  \n",
       "13            P  \n",
       "14            P  \n",
       "15            P  \n",
       "16            P  \n",
       "17            P  \n",
       "18            P  \n",
       "19            P  \n",
       "20            P  \n",
       "21            P  \n",
       "22            P  \n",
       "23            P  \n",
       "24            P  \n",
       "25            P  \n",
       "26            P  \n",
       "27            P  \n",
       "28            P  \n",
       "29            P  \n",
       "..          ...  \n",
       "931           P  \n",
       "932           P  \n",
       "933           P  \n",
       "934           P  \n",
       "935           P  \n",
       "936           P  \n",
       "937           P  \n",
       "938           P  \n",
       "939           P  \n",
       "940           P  \n",
       "941           P  \n",
       "942           P  \n",
       "943           P  \n",
       "944           P  \n",
       "945           P  \n",
       "946           P  \n",
       "947           P  \n",
       "948           P  \n",
       "949           P  \n",
       "950           P  \n",
       "951           P  \n",
       "952           P  \n",
       "953           P  \n",
       "954           P  \n",
       "955           P  \n",
       "956           P  \n",
       "957           P  \n",
       "958           P  \n",
       "959           P  \n",
       "960           P  \n",
       "\n",
       "[961 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(url, sep='\\t', comment='#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's our data! The first row (remember that Python starts indexing at 0) doesn't belong to the data, so we can use the parameter `skiprows` to ignore it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(url, header=1, sep='\\t', comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5s</th>\n",
       "      <th>15s</th>\n",
       "      <th>20d</th>\n",
       "      <th>6s</th>\n",
       "      <th>14n</th>\n",
       "      <th>10s</th>\n",
       "      <th>14n.1</th>\n",
       "      <th>10s.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USGS</td>\n",
       "      <td>9380000</td>\n",
       "      <td>2016-01-01 00:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>15200</td>\n",
       "      <td>P</td>\n",
       "      <td>9.74</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USGS</td>\n",
       "      <td>9380000</td>\n",
       "      <td>2016-01-01 00:15</td>\n",
       "      <td>MST</td>\n",
       "      <td>14900</td>\n",
       "      <td>P</td>\n",
       "      <td>9.67</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USGS</td>\n",
       "      <td>9380000</td>\n",
       "      <td>2016-01-01 00:30</td>\n",
       "      <td>MST</td>\n",
       "      <td>14600</td>\n",
       "      <td>P</td>\n",
       "      <td>9.62</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USGS</td>\n",
       "      <td>9380000</td>\n",
       "      <td>2016-01-01 00:45</td>\n",
       "      <td>MST</td>\n",
       "      <td>14200</td>\n",
       "      <td>P</td>\n",
       "      <td>9.55</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USGS</td>\n",
       "      <td>9380000</td>\n",
       "      <td>2016-01-01 01:00</td>\n",
       "      <td>MST</td>\n",
       "      <td>14000</td>\n",
       "      <td>P</td>\n",
       "      <td>9.49</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     5s      15s               20d   6s    14n 10s  14n.1 10s.1\n",
       "0  USGS  9380000  2016-01-01 00:00  MST  15200   P   9.74     P\n",
       "1  USGS  9380000  2016-01-01 00:15  MST  14900   P   9.67     P\n",
       "2  USGS  9380000  2016-01-01 00:30  MST  14600   P   9.62     P\n",
       "3  USGS  9380000  2016-01-01 00:45  MST  14200   P   9.55     P\n",
       "4  USGS  9380000  2016-01-01 01:00  MST  14000   P   9.49     P"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
